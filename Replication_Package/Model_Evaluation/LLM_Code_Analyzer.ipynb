{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code for Code Explaination\n"
      ],
      "metadata": {
        "id": "zPNA4INhEmJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "OPENAI_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
        "DEEPSEEK_ENDPOINT = \"https://api.deepseek.com/chat/completions\"\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\"\n",
        "\n",
        "def get_openai_response(prompt_text: str,  api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"OPENAI_API_KEY\":\n",
        "        return \"OpenAI API Key not configured. Please set OPENAI_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(OPENAI_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to OpenAI API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from OpenAI API: {response.text}\"\n",
        "\n",
        "def get_deepseek_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"YOUR_DEEPSEEK_API_KEY\":\n",
        "        return \"Deepseek API Key not configured. Please set DEEPSEEK_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-chat\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(DEEPSEEK_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Deepseek API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from Deepseek API: {response.text}\"\n",
        "\n",
        "def get_gemini_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    chat_history = []\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt_text}]})\n",
        "\n",
        "    payload = {\"contents\": chat_history}\n",
        "    api_url = f\"{GEMINI_ENDPOINT}?key={api_key}\"\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get('candidates') and result['candidates'][0].get('content') and \\\n",
        "           result['candidates'][0]['content'].get('parts') and \\\n",
        "           result['candidates'][0]['content']['parts'][0].get('text'):\n",
        "            return result['candidates'][0]['content']['parts'][0]['text'].strip()\n",
        "        else:\n",
        "            return f\"Unexpected response format from Gemini API: {response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Gemini API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred with Gemini API: {e}\"\n",
        "\n",
        "def add_to_google_sheet(data):\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    # Create a new spreadsheet or open an existing one\n",
        "    try:\n",
        "        sh = gc.open(\"LLM_Code_Analysis\")\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        sh = gc.create(\"LLM_Code_Analysis\")\n",
        "        # Share with yourself to have permission to view it in Google Drive\n",
        "        sh.share(userdata.get('EMAIL'), perm_type='user', role='writer')\n",
        "\n",
        "    worksheet = sh.sheet1\n",
        "\n",
        "    # Append data to the next available row\n",
        "    worksheet.append_row(data)\n",
        "def get_prompts_from_sheet():\n",
        "    # Authenticate and access the sheet\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    # Open the spreadsheet and the \"Explanation\" sheet\n",
        "    sheet = gc.open(\"ASE Tool Dataset\").worksheet(\"Explanation\")\n",
        "\n",
        "    # Fetch the prompts from the \"Prompt to Code\" column\n",
        "    prompt_data = sheet.col_values(5)  # This fetches the entire column\n",
        "\n",
        "    # Skip the header and return the prompts\n",
        "    return prompt_data[1:31]\n",
        "\n",
        "# --- Main Logic ---\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the LLM Code Analyzer!\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    prompts = get_prompts_from_sheet()\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nGetting responses from LLMs...\\n\")\n",
        "\n",
        " for i, user_prompt in enumerate(prompts, start=1):\n",
        "    # Get response from GPT-4o\n",
        "    print(\"--- GPT-4o Response ---\")\n",
        "    gpt_response = get_openai_response(user_prompt, OPENAI_API_KEY)\n",
        "    print(gpt_response[1])\n",
        "    print(\"-\" * 30)\n",
        "    # Get response from Deepseek\n",
        "    print(\"\\n--- Deepseek Response ---\")\n",
        "    deepseek_response = get_deepseek_response(user_prompt,  DEEPSEEK_API_KEY)\n",
        "    print(deepseek_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Gemini\n",
        "    print(\"\\n--- Gemini Response ---\")\n",
        "    gemini_response = get_gemini_response(user_prompt, GEMINI_API_KEY)\n",
        "    print(gemini_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Add results to Google Sheet\n",
        "    sheet_data = [f\"Prompt {i}\", gpt_response, deepseek_response, gemini_response]\n",
        "    add_to_google_sheet(sheet_data)\n",
        "    print(\"Results added to Google Sheet.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the LLM Code Analyzer!\n",
            "------------------------------\n",
            "\n",
            "Getting responses from LLMs...\n",
            "\n",
            "--- GPT-4o Response ---\n",
            "### Context of the Project Repository\n",
            "In the context of the Keel project repository, `Sobel.java` implements an edge detection algorithm using the Sobel filter. This code processes height maps in greyscale to enhance and outline features within the image, contributing to any image processing tasks that require edge detection or analysis.\n",
            "\n",
            "### Explanation of the Code\n",
            "The `Sobel.java` file is part of the `com.harium.keel.effect.height` package and implements edge detection using the Sobel filter. As an implementation of the `Effect` interface, it takes a grayscale height map as input (`ImageSource`) and returns an image highlighting edges (`MatrixSource`). The algorithm iterates over pixel values, applying the Sobel operator to compute the gradient magnitudes in both x and y directions. This involves a convolution approach with pre-defined Sobel matrices to detect intensity changes and produce a resulting image emphasizing edges.\n",
            "\n",
            "### Method Descriptions\n",
            "\n",
            "- **apply(ImageSource input)**: Takes a grayscale image as input, applies the Sobel filter, and outputs an image with edges detected.\n",
            "- **convolution(int[][] pixelMatrix)**: Calculates the gradient magnitude using Sobel operators to detect edges in the pixel matrix.\n",
            "------------------------------\n",
            "Results added to Google Sheet.\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887e7196-38df-48f5-a152-28d3e4b158e8",
        "id": "9-y1vO8zKkCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for Code Quality Metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "vmkm6NZ6Ezhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# API Endpoints\n",
        "OPENAI_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
        "DEEPSEEK_ENDPOINT = \"https://api.deepseek.com/chat/completions\"\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\"\n",
        "\n",
        "# --- Helper Functions for LLM Interactions ---\n",
        "\n",
        "def get_openai_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"OPENAI_API_KEY\":\n",
        "        return \"OpenAI API Key not configured. Please set OPENAI_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(OPENAI_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to OpenAI API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from OpenAI API: {response.text}\"\n",
        "\n",
        "def get_deepseek_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"YOUR_DEEPSEEK_API_KEY\":\n",
        "        return \"Deepseek API Key not configured. Please set DEEPSEEK_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-chat\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(DEEPSEEK_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Deepseek API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from Deepseek API: {response.text}\"\n",
        "\n",
        "def get_gemini_response(prompt_text: str,  api_key: str) -> str:\n",
        "\n",
        "    chat_history = []\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt_text}]})\n",
        "\n",
        "\n",
        "    payload = {\"contents\": chat_history}\n",
        "    api_url = f\"{GEMINI_ENDPOINT}?key={api_key}\"\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get('candidates') and result['candidates'][0].get('content') and \\\n",
        "           result['candidates'][0]['content'].get('parts') and \\\n",
        "           result['candidates'][0]['content']['parts'][0].get('text'):\n",
        "            return result['candidates'][0]['content']['parts'][0]['text'].strip()\n",
        "        else:\n",
        "            return f\"Unexpected response format from Gemini API: {response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Gemini API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred with Gemini API: {e}\"\n",
        "\n",
        "def add_to_google_sheet(data):\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    # Create a new spreadsheet or open an existing one\n",
        "    try:\n",
        "        sh = gc.open(\"LLM_Code_Analysis\")\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        sh = gc.create(\"LLM_Code_Analysis\")\n",
        "        # Share with yourself to have permission to view it in Google Drive\n",
        "        sh.share(userdata.get('EMAIL'), perm_type='user', role='writer')\n",
        "\n",
        "    worksheet = sh.sheet1\n",
        "\n",
        "    # Append data to the next available row\n",
        "    worksheet.append_row(data)\n",
        "def get_prompts_from_sheet():\n",
        "    # Authenticate and access the sheet\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "\n",
        "    sheet = gc.open(\"ASE Tool Dataset\").worksheet(\"Code Metics\")\n",
        "\n",
        "    # Fetch the prompts from the \"Prompt to Code\" column\n",
        "    prompt_data = sheet.col_values(5)  # This fetches the entire column\n",
        "\n",
        "    # Skip the header and return the prompts\n",
        "    return prompt_data[1:31]\n",
        "\n",
        "# --- Main Logic ---\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the LLM Code Analyzer!\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    prompts = get_prompts_from_sheet()\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nGetting responses from LLMs...\\n\")\n",
        "\n",
        " for i, user_prompt in enumerate(prompts, start=1):\n",
        "    # Get response from GPT-4o\n",
        "    print(\"--- GPT-4o Response ---\")\n",
        "    gpt_response = get_openai_response(user_prompt, OPENAI_API_KEY)\n",
        "    print(gpt_response[1])\n",
        "    print(\"-\" * 30)\n",
        "    # Get response from Deepseek\n",
        "    print(\"\\n--- Deepseek Response ---\")\n",
        "    deepseek_response = get_deepseek_response(user_prompt,  DEEPSEEK_API_KEY)\n",
        "    print(deepseek_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Gemini\n",
        "    print(\"\\n--- Gemini Response ---\")\n",
        "    gemini_response = get_gemini_response(user_prompt, GEMINI_API_KEY)\n",
        "    print(gemini_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Add results to Google Sheet\n",
        "    sheet_data = [f\"Prompt {i}\", gpt_response, deepseek_response, gemini_response]\n",
        "    add_to_google_sheet(sheet_data)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the LLM Code Analyzer!\n",
            "------------------------------\n",
            "\n",
            "Getting responses from LLMs...\n",
            "\n",
            "--- GPT-4o Response ---\n",
            "Cyclomatic Complexity: 22  \n",
            "Maintainability Index: 90  \n",
            "Vulnerability Category: Memory Corruption\n",
            "------------------------------\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "39Jl_fUWO-iD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b1551f-2978-4330-ab80-10bfcc2561ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2mcDiiA0Vpun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for Code Refactoring\n"
      ],
      "metadata": {
        "id": "w0oFqDwQE7K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# API Endpoints\n",
        "OPENAI_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
        "DEEPSEEK_ENDPOINT = \"https://api.deepseek.com/chat/completions\"\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\"\n",
        "\n",
        "# --- Helper Functions for LLM Interactions ---\n",
        "\n",
        "def get_openai_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"OPENAI_API_KEY\":\n",
        "        return \"OpenAI API Key not configured. Please set OPENAI_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(OPENAI_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to OpenAI API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from OpenAI API: {response.text}\"\n",
        "\n",
        "def get_deepseek_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"YOUR_DEEPSEEK_API_KEY\":\n",
        "        return \"Deepseek API Key not configured. Please set DEEPSEEK_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-chat\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(DEEPSEEK_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Deepseek API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from Deepseek API: {response.text}\"\n",
        "\n",
        "def get_gemini_response(prompt_text: str,  api_key: str) -> str:\n",
        "\n",
        "    chat_history = []\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt_text}]})\n",
        "\n",
        "\n",
        "    payload = {\"contents\": chat_history}\n",
        "    api_url = f\"{GEMINI_ENDPOINT}?key={api_key}\"\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get('candidates') and result['candidates'][0].get('content') and \\\n",
        "           result['candidates'][0]['content'].get('parts') and \\\n",
        "           result['candidates'][0]['content']['parts'][0].get('text'):\n",
        "            return result['candidates'][0]['content']['parts'][0]['text'].strip()\n",
        "        else:\n",
        "            return f\"Unexpected response format from Gemini API: {response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Gemini API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred with Gemini API: {e}\"\n",
        "\n",
        "def add_to_google_sheet(data):\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    # Create a new spreadsheet or open an existing one\n",
        "    try:\n",
        "        sh = gc.open(\"LLM_Code_Analysis\")\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        sh = gc.create(\"LLM_Code_Analysis\")\n",
        "        # Share with yourself to have permission to view it in Google Drive\n",
        "        sh.share(userdata.get('EMAIL'), perm_type='user', role='writer')\n",
        "\n",
        "    worksheet = sh.sheet1\n",
        "\n",
        "    # Append data to the next available row\n",
        "    worksheet.append_row(data)\n",
        "def get_prompts_from_sheet():\n",
        "    # Authenticate and access the sheet\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "\n",
        "    sheet = gc.open(\"ASE Tool Dataset\").worksheet(\"Refactoring\")\n",
        "\n",
        "    # Fetch the prompts from the \"Prompt to Code\" column\n",
        "    prompt_data = sheet.col_values(5)  # This fetches the entire column\n",
        "\n",
        "    # Skip the header and return the prompts\n",
        "    return prompt_data[1:31]\n",
        "# --- Main Logic ---\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the LLM Code Analyzer!\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    prompts = get_prompts_from_sheet()\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nGetting responses from LLMs...\\n\")\n",
        "\n",
        " for i, user_prompt in enumerate(prompts, start=1):\n",
        "    # Get response from GPT-4o\n",
        "\n",
        "    print(\"--- GPT-4o Response ---\")\n",
        "    gpt_response = get_openai_response(user_prompt, OPENAI_API_KEY)\n",
        "    print(gpt_response[1])\n",
        "    print(\"-\" * 30)\n",
        "    # Get response from Deepseek\n",
        "    print(\"\\n--- Deepseek Response ---\")\n",
        "    deepseek_response = get_deepseek_response(user_prompt,  DEEPSEEK_API_KEY)\n",
        "    print(deepseek_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Gemini\n",
        "    print(\"\\n--- Gemini Response ---\")\n",
        "    gemini_response = get_gemini_response(user_prompt, GEMINI_API_KEY)\n",
        "    print(gemini_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Add results to Google Sheet\n",
        "    sheet_data = [f\"Prompt {i}\", gpt_response, deepseek_response, gemini_response]\n",
        "    add_to_google_sheet(sheet_data)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the LLM Code Analyzer!\n",
            "------------------------------\n",
            "\n",
            "Getting responses from LLMs...\n",
            "\n",
            "--- GPT-4o Response ---\n",
            "```java\n",
            "public Object streamLoad(HttpServletRequest request,\n",
            "                         @PathVariable(value = DB_KEY) String db,\n",
            "                         @PathVariable(value = TABLE_KEY) String table) {\n",
            "    if (isGroupCommitEnabled(request)) { // Extracted repeated logic into a separate method\n",
            "        try {\n",
            "            String[] pair = new String[]{db, table};\n",
            "            if (isGroupCommitBlock(pair)) {\n",
            "                return new RestBaseResult(\"insert table \" + pair[1] + \" is blocked on schema change\");\n",
            "            }\n",
            "        } catch (Exception e) {\n",
            "            // handle\n",
            "        }\n",
            "    }\n",
            "    return null; // Added return null to ensure method always returns an Object\n",
            "}\n",
            "\n",
            "@RequestMapping(path = \"/api/_http_stream\", method = RequestMethod.PUT)\n",
            "public Object streamLoadWithSql(HttpServletRequest request, HttpServletResponse response) {\n",
            "    String sql = request.getHeader(\"sql\");\n",
            "    LOG.info(\"streaming load sql={}\", sql);\n",
            "    if (isGroupCommitEnabled(request)) { // Reused extracted method for group commit logic\n",
            "        try {\n",
            "            String[] pair = parseDbAndTb(sql);\n",
            "            if (isGroupCommitBlock(pair)) {\n",
            "                return new RestBaseResult(\"insert table \" + pair[1] + \" is blocked on schema change\");\n",
            "            }\n",
            "        } catch (Exception e) {\n",
            "            // handle\n",
            "        }\n",
            "    }\n",
            "    return null; // Added return null to ensure method always returns an Object\n",
            "}\n",
            "\n",
            "private boolean isGroupCommitEnabled(HttpServletRequest request) { // Created new method for repeated logic\n",
            "    String groupCommitStr = request.getHeader(\"group_commit\");\n",
            "    return groupCommitStr != null && groupCommitStr.equals(\"async_mode\");\n",
            "}\n",
            "\n",
            "private boolean isGroupCommitBlock(String[] pair) throws TException {\n",
            "    Database dbObj = getDatabase(pair[0]); // Extracted repeated logic into a separate method\n",
            "    Table tblObj = dbObj.getTableOrException(pair[1], \n",
            "                    s -> new TException(\"table is invalid: \" + s));\n",
            "    return Env.getCurrentEnv().getGroupCommitManager().isBlock(tblObj.getId());\n",
            "}\n",
            "\n",
            "private Database getDatabase(String dbName) throws TException { // New method for fetching Database object\n",
            "    String fullDbName = getFullDbName(dbName);\n",
            "    return Env.getCurrentInternalCatalog().getDbOrException(fullDbName, \n",
            "           s -> new TException(\"database is invalid for dbName: \" + s));\n",
            "}\n",
            "```\n",
            "------------------------------\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969559cc-b524-43e0-8c44-32693a24d14a",
        "id": "ctl_WIffRwvQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}