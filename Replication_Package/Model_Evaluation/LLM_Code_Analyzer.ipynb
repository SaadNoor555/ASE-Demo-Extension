{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code for Code Explaination\n"
      ],
      "metadata": {
        "id": "zPNA4INhEmJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "OPENAI_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
        "DEEPSEEK_ENDPOINT = \"https://api.deepseek.com/chat/completions\"\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\"\n",
        "\n",
        "def get_openai_response(prompt_text: str,  api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"OPENAI_API_KEY\":\n",
        "        return \"OpenAI API Key not configured. Please set OPENAI_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(OPENAI_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to OpenAI API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from OpenAI API: {response.text}\"\n",
        "\n",
        "def get_deepseek_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"YOUR_DEEPSEEK_API_KEY\":\n",
        "        return \"Deepseek API Key not configured. Please set DEEPSEEK_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-chat\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(DEEPSEEK_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Deepseek API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from Deepseek API: {response.text}\"\n",
        "\n",
        "def get_gemini_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    chat_history = []\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt_text}]})\n",
        "\n",
        "    payload = {\"contents\": chat_history}\n",
        "    api_url = f\"{GEMINI_ENDPOINT}?key={api_key}\"\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get('candidates') and result['candidates'][0].get('content') and \\\n",
        "           result['candidates'][0]['content'].get('parts') and \\\n",
        "           result['candidates'][0]['content']['parts'][0].get('text'):\n",
        "            return result['candidates'][0]['content']['parts'][0]['text'].strip()\n",
        "        else:\n",
        "            return f\"Unexpected response format from Gemini API: {response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Gemini API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred with Gemini API: {e}\"\n",
        "\n",
        "def add_to_google_sheet(data):\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    # Create a new spreadsheet or open an existing one\n",
        "    try:\n",
        "        sh = gc.open(\"LLM_Code_Analysis\")\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        sh = gc.create(\"LLM_Code_Analysis\")\n",
        "        # Share with yourself to have permission to view it in Google Drive\n",
        "        sh.share(userdata.get('EMAIL'), perm_type='user', role='writer')\n",
        "\n",
        "    worksheet = sh.sheet1\n",
        "\n",
        "    # Append data to the next available row\n",
        "    worksheet.append_row(data)\n",
        "\n",
        "\n",
        "# --- Main Logic ---\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the LLM Code Analyzer!\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    user_prompt = \"\"\"\n",
        "    In a GitHub repo titled Keel the following code files exist 'src/main/java/com/harium/keel/effect/height/Sobel.java'\n",
        "\n",
        "    Explain the file called: sobel.java.First in 40-50 words explain what this code file does in the context of the project repository. Then, explain what this code file does(write it in 100-120 words and write 1 small line describing each method in the code.)\n",
        "    package com.harium.keel.effect.height; First in 40-50 words explain what this code file does in the context of the project repository. Then, explain what this code file does(write it in 100-120 words and write 1 small line describing each method in the code.)\n",
        "    import com.harium.keel.core.Effect;\n",
        "    import com.harium.keel.core.source.ImageSource;\n",
        "    import com.harium.keel.core.source.MatrixSource;\n",
        "\n",
        "    /**\n",
        "     * Sobel Filter\n",
        "     * Code from: https://stackoverflow.com/a/30511674\n",
        "     */\n",
        "    public class Sobel implements Effect {\n",
        "\n",
        "        /**\n",
        "         * Expects a height mat as input\n",
        "         *\n",
        "         * @param input - A grayscale height map\n",
        "         * @return edges\n",
        "         */\n",
        "        @Override\n",
        "        public ImageSource apply(ImageSource input) {\n",
        "            final int[][] pixelMatrix = new int[3][3];\n",
        "\n",
        "            int w = input.getWidth();\n",
        "            int h = input.getHeight();\n",
        "\n",
        "            int[][] output = new int[h][w];\n",
        "\n",
        "            for (int j = 1; j < h - 1; j++) {\n",
        "                for (int i = 1; i < w - 1; i++) {\n",
        "                    pixelMatrix[0][0] = input.getR(i - 1, j - 1);\n",
        "                    pixelMatrix[0][1] = input.getRGB(i - 1, j);\n",
        "                    pixelMatrix[0][2] = input.getRGB(i - 1, j + 1);\n",
        "                    pixelMatrix[1][0] = input.getRGB(i, j - 1);\n",
        "                    pixelMatrix[1][2] = input.getRGB(i, j + 1);\n",
        "                    pixelMatrix[2][0] = input.getRGB(i + 1, j - 1);\n",
        "                    pixelMatrix[2][1] = input.getRGB(i + 1, j);\n",
        "                    pixelMatrix[2][2] = input.getRGB(i + 1, j + 1);\n",
        "\n",
        "                    int edge = (int) convolution(pixelMatrix);\n",
        "                    int rgb = (edge << 16 | edge << 8 | edge);\n",
        "                    output[j][i] = rgb;\n",
        "                }\n",
        "            }\n",
        "\n",
        "            MatrixSource source = new MatrixSource(output);\n",
        "            return source;\n",
        "        }\n",
        "\n",
        "        private static double convolution(int[][] pixelMatrix) {\n",
        "            int gy = (pixelMatrix[0][0] * -1) + (pixelMatrix[0][1] * -2) + (pixelMatrix[0][2] * -1) + (pixelMatrix[2][0]) + (pixelMatrix[2][1] * 2) + (pixelMatrix[2][2] * 1);\n",
        "            int gx = (pixelMatrix[0][0]) + (pixelMatrix[0][2] * -1) + (pixelMatrix[1][0] * 2) + (pixelMatrix[1][2] * -2) + (pixelMatrix[2][0]) + (pixelMatrix[2][2] * -1);\n",
        "\n",
        "            return Math.sqrt(Math.pow(gy, 2) + Math.pow(gx, 2));\n",
        "        }\n",
        "\n",
        "    }in context of the project.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nGetting responses from LLMs...\\n\")\n",
        "\n",
        "    # Get response from GPT-4o\n",
        "    print(\"--- GPT-4o Response ---\")\n",
        "    gpt_response = get_openai_response(user_prompt, OPENAI_API_KEY)\n",
        "    print(gpt_response)\n",
        "    print(\"-\" * 30)\n",
        "    # Get response from Deepseek\n",
        "    print(\"\\n--- Deepseek Response ---\")\n",
        "    deepseek_response = get_deepseek_response(user_prompt,  DEEPSEEK_API_KEY)\n",
        "    print(deepseek_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Gemini\n",
        "    print(\"\\n--- Gemini Response ---\")\n",
        "    gemini_response = get_gemini_response(user_prompt, GEMINI_API_KEY)\n",
        "    print(gemini_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Add results to Google Sheet\n",
        "    sheet_data = [\"Code Explanation\", gpt_response, deepseek_response, gemini_response]\n",
        "    add_to_google_sheet(sheet_data)\n",
        "    print(\"Results added to Google Sheet.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the LLM Code Analyzer!\n",
            "------------------------------\n",
            "\n",
            "Getting responses from LLMs...\n",
            "\n",
            "--- GPT-4o Response ---\n",
            "### Context of the Project Repository\n",
            "In the context of the Keel project repository, `Sobel.java` implements an edge detection algorithm using the Sobel filter. This code processes height maps in greyscale to enhance and outline features within the image, contributing to any image processing tasks that require edge detection or analysis.\n",
            "\n",
            "### Explanation of the Code\n",
            "The `Sobel.java` file is part of the `com.harium.keel.effect.height` package and implements edge detection using the Sobel filter. As an implementation of the `Effect` interface, it takes a grayscale height map as input (`ImageSource`) and returns an image highlighting edges (`MatrixSource`). The algorithm iterates over pixel values, applying the Sobel operator to compute the gradient magnitudes in both x and y directions. This involves a convolution approach with pre-defined Sobel matrices to detect intensity changes and produce a resulting image emphasizing edges.\n",
            "\n",
            "### Method Descriptions\n",
            "\n",
            "- **apply(ImageSource input)**: Takes a grayscale image as input, applies the Sobel filter, and outputs an image with edges detected.\n",
            "- **convolution(int[][] pixelMatrix)**: Calculates the gradient magnitude using Sobel operators to detect edges in the pixel matrix.\n",
            "------------------------------\n",
            "Results added to Google Sheet.\n"
          ]
        }
      ],
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887e7196-38df-48f5-a152-28d3e4b158e8",
        "id": "9-y1vO8zKkCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for Code Quality Metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "vmkm6NZ6Ezhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# API Endpoints\n",
        "OPENAI_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
        "DEEPSEEK_ENDPOINT = \"https://api.deepseek.com/chat/completions\"\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\"\n",
        "\n",
        "# --- Helper Functions for LLM Interactions ---\n",
        "\n",
        "def get_openai_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"OPENAI_API_KEY\":\n",
        "        return \"OpenAI API Key not configured. Please set OPENAI_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(OPENAI_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to OpenAI API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from OpenAI API: {response.text}\"\n",
        "\n",
        "def get_deepseek_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"YOUR_DEEPSEEK_API_KEY\":\n",
        "        return \"Deepseek API Key not configured. Please set DEEPSEEK_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-chat\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(DEEPSEEK_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Deepseek API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from Deepseek API: {response.text}\"\n",
        "\n",
        "def get_gemini_response(prompt_text: str,  api_key: str) -> str:\n",
        "\n",
        "    chat_history = []\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt_text}]})\n",
        "\n",
        "\n",
        "    payload = {\"contents\": chat_history}\n",
        "    api_url = f\"{GEMINI_ENDPOINT}?key={api_key}\"\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get('candidates') and result['candidates'][0].get('content') and \\\n",
        "           result['candidates'][0]['content'].get('parts') and \\\n",
        "           result['candidates'][0]['content']['parts'][0].get('text'):\n",
        "            return result['candidates'][0]['content']['parts'][0]['text'].strip()\n",
        "        else:\n",
        "            return f\"Unexpected response format from Gemini API: {response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Gemini API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred with Gemini API: {e}\"\n",
        "\n",
        "def add_to_google_sheet(data):\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    # Create a new spreadsheet or open an existing one\n",
        "    try:\n",
        "        sh = gc.open(\"LLM_Code_Analysis\")\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        sh = gc.create(\"LLM_Code_Analysis\")\n",
        "        # Share with yourself to have permission to view it in Google Drive\n",
        "        sh.share(userdata.get('EMAIL'), perm_type='user', role='writer')\n",
        "\n",
        "    worksheet = sh.sheet1\n",
        "\n",
        "    # Append data to the next available row\n",
        "    worksheet.append_row(data)\n",
        "\n",
        "\n",
        "# --- Main Logic ---\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the LLM Code Analyzer!\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    user_prompt = \"\"\"\n",
        "\"CVE categories :Code Execution,Denial of Service,Information Leak,Privilege Escalation,Overflow,ByPass, Memory Corruption. Calculate the cyclomatic complexity, maintainability index and vulnerability category that suit most from CVE categories for the following code. Just check out the codes and from the code try to answer . just write the numbers:\\n\"\"#include <linux/errno.h>\n",
        "#include <linux/fs.h>\n",
        "#include <linux/slab.h>\n",
        "#include <linux/random.h>\n",
        "\n",
        "#include \"\"\"\"hfsplus_fs.h\"\"\"\"\n",
        "#include \"\"\"\"hfsplus_raw.h\"\"\"\"\n",
        "\n",
        "static inline void hfsplus_instantiate(struct dentry *dentry,\n",
        "                                       struct inode *inode, u32 cnid)\n",
        "{\n",
        "        dentry->d_fsdata = (void *)(unsigned long)cnid;\n",
        "        d_instantiate(dentry, inode);\n",
        "}\n",
        "\n",
        "/* Find the entry inside dir named dentry->d_name */\n",
        "static struct dentry *hfsplus_lookup(struct inode *dir, struct dentry *dentry,\n",
        "                                     struct nameidata *nd)\n",
        "{\n",
        "        struct inode *inode = NULL;\n",
        "        struct hfs_find_data fd;\n",
        "        struct super_block *sb;\n",
        "        hfsplus_cat_entry entry;\n",
        "        int err;\n",
        "        u32 cnid, linkid = 0;\n",
        "        u16 type;\n",
        "\n",
        "        sb = dir->i_sb;\n",
        "\n",
        "        dentry->d_fsdata = NULL;\n",
        "        err = hfs_find_init(HFSPLUS_SB(sb)->cat_tree, &fd);\n",
        "        if (err)\n",
        "                return ERR_PTR(err);\n",
        "        hfsplus_cat_build_key(sb, fd.search_key, dir->i_ino, &dentry->d_name);\n",
        "again:\n",
        "        err = hfs_brec_read(&fd, &entry, sizeof(entry));\n",
        "        if (err) {\n",
        "                if (err == -ENOENT) {\n",
        "                        hfs_find_exit(&fd);\n",
        "                        /* No such entry */\n",
        "                        inode = NULL;\n",
        "                        goto out;\n",
        "                }\n",
        "                goto fail;\n",
        "        }\n",
        "        type = be16_to_cpu(entry.type);\n",
        "        if (type == HFSPLUS_FOLDER) {\n",
        "                if (fd.entrylength < sizeof(struct hfsplus_cat_folder)) {\n",
        "                        err = -EIO;\n",
        "                        goto fail;\n",
        "                }\n",
        "                cnid = be32_to_cpu(entry.folder.id);\n",
        "                dentry->d_fsdata = (void *)(unsigned long)cnid;\n",
        "        } else if (type == HFSPLUS_FILE) {\n",
        "                if (fd.entrylength < sizeof(struct hfsplus_cat_file)) {\n",
        "                        err = -EIO;\n",
        "                        goto fail;\n",
        "                }\n",
        "                cnid = be32_to_cpu(entry.file.id);\n",
        "                if (entry.file.user_info.fdType ==\n",
        "                                cpu_to_be32(HFSP_HARDLINK_TYPE) &&\n",
        "                                entry.file.user_info.fdCreator ==\n",
        "                                cpu_to_be32(HFSP_HFSPLUS_CREATOR) &&\n",
        "                                (entry.file.create_date ==\n",
        "                                        HFSPLUS_I(HFSPLUS_SB(sb)->hidden_dir)->\n",
        "                                                create_date ||\n",
        "                                entry.file.create_date ==\n",
        "                                        HFSPLUS_I(sb->s_root->d_inode)->\n",
        "                                                create_date) &&\n",
        "                                HFSPLUS_SB(sb)->hidden_dir) {\n",
        "                        struct qstr str;\n",
        "                        char name[32];\n",
        "\n",
        "                        if (dentry->d_fsdata) {\n",
        "                                /*\n",
        "                                 * We found a link pointing to another link,\n",
        "                                 * so ignore it and treat it as regular file.\n",
        "                                 */\n",
        "                                cnid = (unsigned long)dentry->d_fsdata;\n",
        "                                linkid = 0;\n",
        "                        } else {\n",
        "                                dentry->d_fsdata = (void *)(unsigned long)cnid;\n",
        "                                linkid =\n",
        "                                        be32_to_cpu(entry.file.permissions.dev);\n",
        "                                str.len = sprintf(name, \"\"\"\"iNode%d\"\"\"\", linkid);\n",
        "                                str.name = name;\n",
        "                                hfsplus_cat_build_key(sb, fd.search_key,\n",
        "                                        HFSPLUS_SB(sb)->hidden_dir->i_ino,\n",
        "                                        &str);\n",
        "                                goto again;\n",
        "                        }\n",
        "                } else if (!dentry->d_fsdata)\n",
        "                        dentry->d_fsdata = (void *)(unsigned long)cnid;\n",
        "        } else {\n",
        "                printk(KERN_ERR \"\"\"\"hfs: invalid catalog entry type in lookup\\n\"\"\"\");\n",
        "                err = -EIO;\n",
        "                goto fail;\n",
        "        }\n",
        "        hfs_find_exit(&fd);\n",
        "        inode = hfsplus_iget(dir->i_sb, cnid);\n",
        "        if (IS_ERR(inode))\n",
        "                return ERR_CAST(inode);\n",
        "        if (S_ISREG(inode->i_mode))\n",
        "                HFSPLUS_I(inode)->linkid = linkid;\n",
        "out:\n",
        "        d_add(dentry, inode);\n",
        "        return NULL;\n",
        "fail:\n",
        "        hfs_find_exit(&fd);\n",
        "        return ERR_PTR(err);\n",
        "}\n",
        "\n",
        "static int hfsplus_readdir(struct file *filp, void *dirent, filldir_t filldir)\n",
        "{\n",
        "        struct inode *inode = filp->f_path.dentry->d_inode;\n",
        "        struct super_block *sb = inode->i_sb;\n",
        "        int len, err;\n",
        "        char strbuf[HFSPLUS_MAX_STRLEN + 1];\n",
        "        hfsplus_cat_entry entry;\n",
        "        struct hfs_find_data fd;\n",
        "        struct hfsplus_readdir_data *rd;\n",
        "        u16 type;\n",
        "\n",
        "        if (filp->f_pos >= inode->i_size)\n",
        "                return 0;\n",
        "\n",
        "        err = hfs_find_init(HFSPLUS_SB(sb)->cat_tree, &fd);\n",
        "        if (err)\n",
        "                return err;\n",
        "        hfsplus_cat_build_key(sb, fd.search_key, inode->i_ino, NULL);\n",
        "        err = hfs_brec_find(&fd);\n",
        "        if (err)\n",
        "                goto out;\n",
        "\n",
        "        switch ((u32)filp->f_pos) {\n",
        "        case 0:\n",
        "                /* This is completely artificial... */\n",
        "                if (filldir(dirent, \"\"\"\".\"\"\"\", 1, 0, inode->i_ino, DT_DIR))\n",
        "                        goto out;\n",
        "                filp->f_pos++;\n",
        "                /* fall through */\n",
        "        case 1:\n",
        "                if (fd.entrylength > sizeof(entry) || fd.entrylength < 0) {\n",
        "                        err = -EIO;\n",
        "                        goto out;\n",
        "                }\n",
        "\n",
        "                hfs_bnode_read(fd.bnode, &entry, fd.entryoffset,\n",
        "                        fd.entrylength);\n",
        "                if (be16_to_cpu(entry.type) != HFSPLUS_FOLDER_THREAD) {\n",
        "                        printk(KERN_ERR \"\"\"\"hfs: bad catalog folder thread\\n\"\"\"\");\n",
        "                        err = -EIO;\n",
        "                        goto out;\n",
        "                }\n",
        "                if (fd.entrylength < HFSPLUS_MIN_THREAD_SZ) {\n",
        "                        printk(KERN_ERR \"\"\"\"hfs: truncated catalog thread\\n\"\"\"\");\n",
        "                        err = -EIO;\n",
        "                        goto out;\n",
        "                }\n",
        "                if (filldir(dirent, \"\"\"\"..\"\"\"\", 2, 1,\n",
        "                            be32_to_cpu(entry.thread.parentID), DT_DIR))\n",
        "                        goto out;\n",
        "                filp->f_pos++;\n",
        "                /* fall through */\n",
        "        default:\n",
        "                if (filp->f_pos >= inode->i_size)\n",
        "                        goto out;\n",
        "                err = hfs_brec_goto(&fd, filp->f_pos - 1);\n",
        "                if (err)\n",
        "                        goto out;\n",
        "        }\n",
        "\n",
        "        for (;;) {\n",
        "                if (be32_to_cpu(fd.key->cat.parent) != inode->i_ino) {\n",
        "                        printk(KERN_ERR \"\"\"\"hfs: walked past end of dir\\n\"\"\"\");\n",
        "                        err = -EIO;\n",
        "                        goto out;\n",
        "                }\n",
        "\n",
        "                if (fd.entrylength > sizeof(entry) || fd.entrylength < 0) {\n",
        "                        err = -EIO;\n",
        "                        goto out;\n",
        "                }\n",
        "\n",
        "                hfs_bnode_read(fd.bnode, &entry, fd.entryoffset,\n",
        "                        fd.entrylength);\n",
        "                type = be16_to_cpu(entry.type);\n",
        "                len = HFSPLUS_MAX_STRLEN;\n",
        "                err = hfsplus_uni2asc(sb, &fd.key->cat.name, strbuf, &len);\n",
        "                if (err)\n",
        "                        goto out;\n",
        "                if (type == HFSPLUS_FOLDER) {\n",
        "                        if (fd.entrylength <\n",
        "                                        sizeof(struct hfsplus_cat_folder)) {\n",
        "                                printk(KERN_ERR \"\"\"\"hfs: small dir entry\\n\"\"\"\");\n",
        "                                err = -EIO;\n",
        "                                goto out;\n",
        "                        }\n",
        "                        if (HFSPLUS_SB(sb)->hidden_dir &&\n",
        "                            HFSPLUS_SB(sb)->hidden_dir->i_ino ==\n",
        "                                        be32_to_cpu(entry.folder.id))\n",
        "                                goto next;\n",
        "                        if (filldir(dirent, strbuf, len, filp->f_pos,\n",
        "                                    be32_to_cpu(entry.folder.id), DT_DIR))\n",
        "                                break;\n",
        "                } else if (type == HFSPLUS_FILE) {\n",
        "                        if (fd.entrylength < sizeof(struct hfsplus_cat_file)) {\n",
        "                                printk(KERN_ERR \"\"\"\"hfs: small file entry\\n\"\"\"\");\n",
        "                                err = -EIO;\n",
        "                                goto out;\n",
        "                        }\n",
        "                        if (filldir(dirent, strbuf, len, filp->f_pos,\n",
        "                                    be32_to_cpu(entry.file.id), DT_REG))\n",
        "                                break;\n",
        "                } else {\n",
        "                        printk(KERN_ERR \"\"\"\"hfs: bad catalog entry type\\n\"\"\"\");\n",
        "                        err = -EIO;\n",
        "                        goto out;\n",
        "                }\n",
        "next:\n",
        "                filp->f_pos++;\n",
        "                if (filp->f_pos >= inode->i_size)\n",
        "                        goto out;\n",
        "                err = hfs_brec_goto(&fd, 1);\n",
        "                if (err)\n",
        "                        goto out;\n",
        "        }\n",
        "        rd = filp->private_data;\n",
        "        if (!rd) {\n",
        "                rd = kmalloc(sizeof(struct hfsplus_readdir_data), GFP_KERNEL);\n",
        "                if (!rd) {\n",
        "                        err = -ENOMEM;\n",
        "                        goto out;\n",
        "                }\n",
        "                filp->private_data = rd;\n",
        "                rd->file = filp;\n",
        "                list_add(&rd->list, &HFSPLUS_I(inode)->open_dir_list);\n",
        "        }\n",
        "        memcpy(&rd->key, fd.key, sizeof(struct hfsplus_cat_key));\n",
        "out:\n",
        "        hfs_find_exit(&fd);\n",
        "        return err;\n",
        "}\n",
        "\n",
        "static int hfsplus_dir_release(struct inode *inode, struct file *file)\n",
        "{\n",
        "        struct hfsplus_readdir_data *rd = file->private_data;\n",
        "        if (rd) {\n",
        "                mutex_lock(&inode->i_mutex);\n",
        "                list_del(&rd->list);\n",
        "                mutex_unlock(&inode->i_mutex);\n",
        "                kfree(rd);\n",
        "        }\n",
        "        return 0;\n",
        "}\n",
        "\n",
        "static int hfsplus_link(struct dentry *src_dentry, struct inode *dst_dir,\n",
        "                        struct dentry *dst_dentry)\n",
        "{\n",
        "        struct hfsplus_sb_info *sbi = HFSPLUS_SB(dst_dir->i_sb);\n",
        "        struct inode *inode = src_dentry->d_inode;\n",
        "        struct inode *src_dir = src_dentry->d_parent->d_inode;\n",
        "        struct qstr str;\n",
        "        char name[32];\n",
        "        u32 cnid, id;\n",
        "        int res;\n",
        "\n",
        "        if (HFSPLUS_IS_RSRC(inode))\n",
        "                return -EPERM;\n",
        "        if (!S_ISREG(inode->i_mode))\n",
        "                return -EPERM;\n",
        "\n",
        "        mutex_lock(&sbi->vh_mutex);\n",
        "        if (inode->i_ino == (u32)(unsigned long)src_dentry->d_fsdata) {\n",
        "                for (;;) {\n",
        "                        get_random_bytes(&id, sizeof(cnid));\n",
        "                        id &= 0x3fffffff;\n",
        "                        str.name = name;\n",
        "                        str.len = sprintf(name, \"\"\"\"iNode%d\"\"\"\", id);\n",
        "                        res = hfsplus_rename_cat(inode->i_ino,\n",
        "                                                 src_dir, &src_dentry->d_name,\n",
        "                                                 sbi->hidden_dir, &str);\n",
        "                        if (!res)\n",
        "                                break;\n",
        "                        if (res != -EEXIST)\n",
        "                                goto out;\n",
        "                }\n",
        "                HFSPLUS_I(inode)->linkid = id;\n",
        "                cnid = sbi->next_cnid++;\n",
        "                src_dentry->d_fsdata = (void *)(unsigned long)cnid;\n",
        "                res = hfsplus_create_cat(cnid, src_dir,\n",
        "                        &src_dentry->d_name, inode);\n",
        "                if (res)\n",
        "                        /* panic? */\n",
        "                        goto out;\n",
        "                sbi->file_count++;\n",
        "        }\n",
        "        cnid = sbi->next_cnid++;\n",
        "        res = hfsplus_create_cat(cnid, dst_dir, &dst_dentry->d_name, inode);\n",
        "        if (res)\n",
        "                goto out;\n",
        "\n",
        "        inc_nlink(inode);\n",
        "        hfsplus_instantiate(dst_dentry, inode, cnid);\n",
        "        ihold(inode);\n",
        "        inode->i_ctime = CURRENT_TIME_SEC;\n",
        "        mark_inode_dirty(inode);\n",
        "        sbi->file_count++;\n",
        "        dst_dir->i_sb->s_dirt = 1;\n",
        "out:\n",
        "        mutex_unlock(&sbi->vh_mutex);\n",
        "        return res;\n",
        "}\n",
        "\n",
        "static int hfsplus_unlink(struct inode *dir, struct dentry *dentry)\n",
        "{\n",
        "        struct hfsplus_sb_info *sbi = HFSPLUS_SB(dir->i_sb);\n",
        "        struct inode *inode = dentry->d_inode;\n",
        "        struct qstr str;\n",
        "        char name[32];\n",
        "        u32 cnid;\n",
        "        int res;\n",
        "\n",
        "        if (HFSPLUS_IS_RSRC(inode))\n",
        "                return -EPERM;\n",
        "\n",
        "        mutex_lock(&sbi->vh_mutex);\n",
        "        cnid = (u32)(unsigned long)dentry->d_fsdata;\n",
        "        if (inode->i_ino == cnid &&\n",
        "            atomic_read(&HFSPLUS_I(inode)->opencnt)) {\n",
        "                str.name = name;\n",
        "                str.len = sprintf(name, \"\"\"\"temp%lu\"\"\"\", inode->i_ino);\n",
        "                res = hfsplus_rename_cat(inode->i_ino,\n",
        "                                         dir, &dentry->d_name,\n",
        "                                         sbi->hidden_dir, &str);\n",
        "                if (!res) {\n",
        "                        inode->i_flags |= S_DEAD;\n",
        "                        drop_nlink(inode);\n",
        "                }\n",
        "                goto out;\n",
        "        }\n",
        "        res = hfsplus_delete_cat(cnid, dir, &dentry->d_name);\n",
        "        if (res)\n",
        "                goto out;\n",
        "\n",
        "        if (inode->i_nlink > 0)\n",
        "                drop_nlink(inode);\n",
        "        if (inode->i_ino == cnid)\n",
        "                clear_nlink(inode);\n",
        "        if (!inode->i_nlink) {\n",
        "                if (inode->i_ino != cnid) {\n",
        "                        sbi->file_count--;\n",
        "                        if (!atomic_read(&HFSPLUS_I(inode)->opencnt)) {\n",
        "                                res = hfsplus_delete_cat(inode->i_ino,\n",
        "                                                         sbi->hidden_dir,\n",
        "                                                         NULL);\n",
        "                                if (!res)\n",
        "                                        hfsplus_delete_inode(inode);\n",
        "                        } else\n",
        "                                inode->i_flags |= S_DEAD;\n",
        "                } else\n",
        "                        hfsplus_delete_inode(inode);\n",
        "        } else\n",
        "                sbi->file_count--;\n",
        "        inode->i_ctime = CURRENT_TIME_SEC;\n",
        "        mark_inode_dirty(inode);\n",
        "out:\n",
        "        mutex_unlock(&sbi->vh_mutex);\n",
        "        return res;\n",
        "}\n",
        "\n",
        "static int hfsplus_rmdir(struct inode *dir, struct dentry *dentry)\n",
        "{\n",
        "        struct hfsplus_sb_info *sbi = HFSPLUS_SB(dir->i_sb);\n",
        "        struct inode *inode = dentry->d_inode;\n",
        "        int res;\n",
        "\n",
        "        if (inode->i_size != 2)\n",
        "                return -ENOTEMPTY;\n",
        "\n",
        "        mutex_lock(&sbi->vh_mutex);\n",
        "        res = hfsplus_delete_cat(inode->i_ino, dir, &dentry->d_name);\n",
        "        if (res)\n",
        "                goto out;\n",
        "        clear_nlink(inode);\n",
        "        inode->i_ctime = CURRENT_TIME_SEC;\n",
        "        hfsplus_delete_inode(inode);\n",
        "        mark_inode_dirty(inode);\n",
        "out:\n",
        "        mutex_unlock(&sbi->vh_mutex);\n",
        "        return res;\n",
        "}\n",
        "\n",
        "static int hfsplus_symlink(struct inode *dir, struct dentry *dentry,\n",
        "                           const char *symname)\n",
        "{\n",
        "        struct hfsplus_sb_info *sbi = HFSPLUS_SB(dir->i_sb);\n",
        "        struct inode *inode;\n",
        "        int res = -ENOSPC;\n",
        "\n",
        "        mutex_lock(&sbi->vh_mutex);\n",
        "        inode = hfsplus_new_inode(dir->i_sb, S_IFLNK | S_IRWXUGO);\n",
        "        if (!inode)\n",
        "                goto out;\n",
        "\n",
        "        res = page_symlink(inode, symname, strlen(symname) + 1);\n",
        "        if (res)\n",
        "                goto out_err;\n",
        "\n",
        "        res = hfsplus_create_cat(inode->i_ino, dir, &dentry->d_name, inode);\n",
        "        if (res)\n",
        "                goto out_err;\n",
        "\n",
        "        hfsplus_instantiate(dentry, inode, inode->i_ino);\n",
        "        mark_inode_dirty(inode);\n",
        "        goto out;\n",
        "\n",
        "out_err:\n",
        "        clear_nlink(inode);\n",
        "        hfsplus_delete_inode(inode);\n",
        "        iput(inode);\n",
        "out:\n",
        "        mutex_unlock(&sbi->vh_mutex);\n",
        "        return res;\n",
        "}\n",
        "\n",
        "static int hfsplus_mknod(struct inode *dir, struct dentry *dentry,\n",
        "                         umode_t mode, dev_t rdev)\n",
        "{\n",
        "        struct hfsplus_sb_info *sbi = HFSPLUS_SB(dir->i_sb);\n",
        "        struct inode *inode;\n",
        "        int res = -ENOSPC;\n",
        "\n",
        "        mutex_lock(&sbi->vh_mutex);\n",
        "        inode = hfsplus_new_inode(dir->i_sb, mode);\n",
        "        if (!inode)\n",
        "                goto out;\n",
        "\n",
        "        if (S_ISBLK(mode) || S_ISCHR(mode) || S_ISFIFO(mode) || S_ISSOCK(mode))\n",
        "                init_special_inode(inode, mode, rdev);\n",
        "\n",
        "        res = hfsplus_create_cat(inode->i_ino, dir, &dentry->d_name, inode);\n",
        "        if (res) {\n",
        "                clear_nlink(inode);\n",
        "                hfsplus_delete_inode(inode);\n",
        "                iput(inode);\n",
        "                goto out;\n",
        "        }\n",
        "\n",
        "        hfsplus_instantiate(dentry, inode, inode->i_ino);\n",
        "        mark_inode_dirty(inode);\n",
        "out:\n",
        "        mutex_unlock(&sbi->vh_mutex);\n",
        "        return res;\n",
        "}\n",
        "\n",
        "static int hfsplus_create(struct inode *dir, struct dentry *dentry, umode_t mode,\n",
        "                          struct nameidata *nd)\n",
        "{\n",
        "        return hfsplus_mknod(dir, dentry, mode, 0);\n",
        "}\n",
        "\n",
        "static int hfsplus_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)\n",
        "{\n",
        "        return hfsplus_mknod(dir, dentry, mode | S_IFDIR, 0);\n",
        "}\n",
        "\n",
        "static int hfsplus_rename(struct inode *old_dir, struct dentry *old_dentry,\n",
        "                          struct inode *new_dir, struct dentry *new_dentry)\n",
        "{\n",
        "        int res;\n",
        "\n",
        "        /* Unlink destination if it already exists */\n",
        "        if (new_dentry->d_inode) {\n",
        "                if (S_ISDIR(new_dentry->d_inode->i_mode))\n",
        "                        res = hfsplus_rmdir(new_dir, new_dentry);\n",
        "                else\n",
        "                        res = hfsplus_unlink(new_dir, new_dentry);\n",
        "                if (res)\n",
        "                        return res;\n",
        "        }\n",
        "\n",
        "        res = hfsplus_rename_cat((u32)(unsigned long)old_dentry->d_fsdata,\n",
        "                                 old_dir, &old_dentry->d_name,\n",
        "                                 new_dir, &new_dentry->d_name);\n",
        "        if (!res)\n",
        "                new_dentry->d_fsdata = old_dentry->d_fsdata;\n",
        "        return res;\n",
        "}\n",
        "\n",
        "const struct inode_operations hfsplus_dir_inode_operations = {\n",
        "        .lookup                = hfsplus_lookup,\n",
        "        .create                = hfsplus_create,\n",
        "        .link                = hfsplus_link,\n",
        "        .unlink                = hfsplus_unlink,\n",
        "        .mkdir                = hfsplus_mkdir,\n",
        "        .rmdir                = hfsplus_rmdir,\n",
        "        .symlink        = hfsplus_symlink,\n",
        "        .mknod                = hfsplus_mknod,\n",
        "        .rename                = hfsplus_rename,\n",
        "};\n",
        "\n",
        "const struct file_operations hfsplus_dir_operations = {\n",
        "        .fsync                = hfsplus_file_fsync,\n",
        "        .read                = generic_read_dir,\n",
        "        .readdir        = hfsplus_readdir,\n",
        "        .unlocked_ioctl = hfsplus_ioctl,\n",
        "        .llseek                = generic_file_llseek,\n",
        "        .release        = hfsplus_dir_release,\n",
        "};\"\"\\n\\nIn your response only give the detected values of these attributes. Don't give any explanation\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nGetting responses from LLMs...\\n\")\n",
        "\n",
        "    # Get response from GPT-4o\n",
        "    print(\"--- GPT-4o Response ---\")\n",
        "    gpt_response = get_openai_response(user_prompt, OPENAI_API_KEY)\n",
        "    print(gpt_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Deepseek\n",
        "    print(\"\\n--- Deepseek Response ---\")\n",
        "    deepseek_response = get_deepseek_response(user_prompt, DEEPSEEK_API_KEY)\n",
        "    print(deepseek_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Gemini\n",
        "    print(\"\\n--- Gemini Response ---\")\n",
        "    gemini_response = get_gemini_response(user_prompt, GEMINI_API_KEY)\n",
        "    print(gemini_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "     # Add results to Google Sheet\n",
        "    sheet_data = [\"Code Explanation\", gpt_response, deepseek_response, gemini_response]\n",
        "    add_to_google_sheet(sheet_data)\n",
        "    print(\"Results added to Google Sheet.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the LLM Code Analyzer!\n",
            "------------------------------\n",
            "\n",
            "Getting responses from LLMs...\n",
            "\n",
            "--- GPT-4o Response ---\n",
            "Cyclomatic Complexity: 22  \n",
            "Maintainability Index: 90  \n",
            "Vulnerability Category: Memory Corruption\n",
            "------------------------------\n"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {
        "id": "39Jl_fUWO-iD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b1551f-2978-4330-ab80-10bfcc2561ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2mcDiiA0Vpun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for Code Refactoring\n"
      ],
      "metadata": {
        "id": "w0oFqDwQE7K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# API Endpoints\n",
        "OPENAI_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
        "DEEPSEEK_ENDPOINT = \"https://api.deepseek.com/chat/completions\"\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\"\n",
        "\n",
        "# --- Helper Functions for LLM Interactions ---\n",
        "\n",
        "def get_openai_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"OPENAI_API_KEY\":\n",
        "        return \"OpenAI API Key not configured. Please set OPENAI_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(OPENAI_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to OpenAI API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from OpenAI API: {response.text}\"\n",
        "\n",
        "def get_deepseek_response(prompt_text: str, api_key: str) -> str:\n",
        "\n",
        "    if not api_key or api_key == \"YOUR_DEEPSEEK_API_KEY\":\n",
        "        return \"Deepseek API Key not configured. Please set DEEPSEEK_API_KEY.\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_text},\n",
        "\n",
        "    ]\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-chat\",\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(DEEPSEEK_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Deepseek API: {e}\"\n",
        "    except KeyError:\n",
        "        return f\"Unexpected response format from Deepseek API: {response.text}\"\n",
        "\n",
        "def get_gemini_response(prompt_text: str,  api_key: str) -> str:\n",
        "\n",
        "    chat_history = []\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt_text}]})\n",
        "\n",
        "\n",
        "    payload = {\"contents\": chat_history}\n",
        "    api_url = f\"{GEMINI_ENDPOINT}?key={api_key}\"\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get('candidates') and result['candidates'][0].get('content') and \\\n",
        "           result['candidates'][0]['content'].get('parts') and \\\n",
        "           result['candidates'][0]['content']['parts'][0].get('text'):\n",
        "            return result['candidates'][0]['content']['parts'][0]['text'].strip()\n",
        "        else:\n",
        "            return f\"Unexpected response format from Gemini API: {response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to Gemini API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred with Gemini API: {e}\"\n",
        "\n",
        "def add_to_google_sheet(data):\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    # Create a new spreadsheet or open an existing one\n",
        "    try:\n",
        "        sh = gc.open(\"LLM_Code_Analysis\")\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        sh = gc.create(\"LLM_Code_Analysis\")\n",
        "        # Share with yourself to have permission to view it in Google Drive\n",
        "        sh.share(userdata.get('EMAIL'), perm_type='user', role='writer')\n",
        "\n",
        "    worksheet = sh.sheet1\n",
        "\n",
        "    # Append data to the next available row\n",
        "    worksheet.append_row(data)\n",
        "\n",
        "# --- Main Logic ---\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the LLM Code Analyzer!\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    user_prompt = \"\"\"\n",
        "Refactor the following code file and provide the complete, cleaned, and refactored version as output.\n",
        "Include brief comments (12 to 15 words) next to each section where refactoring was performed,\n",
        "explaining the changes made. Do not include any additional explanations or descriptions,\n",
        "just give the refactored code as output:\n",
        "\n",
        "public Object streamLoad(HttpServletRequest request,\n",
        "                         @PathVariable(value = DB_KEY) String db,\n",
        "                         @PathVariable(value = TABLE_KEY) String table) {\n",
        "    boolean groupCommit = false;\n",
        "    String groupCommitStr = request.getHeader(\"group_commit\");\n",
        "    if (groupCommitStr != null && groupCommitStr.equals(\"async_mode\")) {\n",
        "        groupCommit = true;\n",
        "        try {\n",
        "            String[] pair = new String[] {db, table};\n",
        "            if (isGroupCommitBlock(pair)) {\n",
        "                String msg = \"insert table \" + pair[1] + \" is blocked on schema change\";\n",
        "                return new RestBaseResult(msg);\n",
        "            }\n",
        "        } catch (Exception e) {\n",
        "            // handle\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "@RequestMapping(path = \"/api/_http_stream\", method = RequestMethod.PUT)\n",
        "public Object streamLoadWithSql(HttpServletRequest request, HttpServletResponse response) {\n",
        "    String sql = request.getHeader(\"sql\");\n",
        "    LOG.info(\"streaming load sql={}\", sql);\n",
        "    boolean groupCommit = false;\n",
        "    String groupCommitStr = request.getHeader(\"group_commit\");\n",
        "    if (groupCommitStr != null && groupCommitStr.equals(\"async_mode\")) {\n",
        "        groupCommit = true;\n",
        "        try {\n",
        "            String[] pair = parseDbAndTb(sql);\n",
        "            if (isGroupCommitBlock(pair)) {\n",
        "                String msg = \"insert table \" + pair[1] + \" is blocked on schema change\";\n",
        "                return new RestBaseResult(msg);\n",
        "            }\n",
        "        } catch (Exception e) {\n",
        "            // handle\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "private boolean isGroupCommitBlock(String[] pair) throws TException {\n",
        "    String fullDbName = getFullDbName(pair[0]);\n",
        "    Database dbObj = Env.getCurrentInternalCatalog()\n",
        "                        .getDbOrException(fullDbName, s -> new TException(\"database is invalid for dbName: \" + s));\n",
        "    Table tblObj = dbObj.getTableOrException(pair[1], s -> new TException(\"table is invalid: \" + s));\n",
        "    return Env.getCurrentEnv().getGroupCommitManager().isBlock(tblObj.getId());\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nGetting responses from LLMs...\\n\")\n",
        "\n",
        "    # Get response from GPT-4o\n",
        "    print(\"--- GPT-4o Response ---\")\n",
        "    gpt_response = get_openai_response(user_prompt, OPENAI_API_KEY)\n",
        "    print(gpt_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Deepseek\n",
        "    print(\"\\n--- Deepseek Response ---\")\n",
        "    deepseek_response = get_deepseek_response(user_prompt, DEEPSEEK_API_KEY)\n",
        "    print(deepseek_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Get response from Gemini\n",
        "    print(\"\\n--- Gemini Response ---\")\n",
        "    gemini_response = get_gemini_response(user_prompt, GEMINI_API_KEY)\n",
        "    print(gemini_response)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "     # Add results to Google Sheet\n",
        "    sheet_data = [\"Code Explanation\", gpt_response, deepseek_response, gemini_response]\n",
        "    add_to_google_sheet(sheet_data)\n",
        "    print(\"Results added to Google Sheet.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the LLM Code Analyzer!\n",
            "------------------------------\n",
            "\n",
            "Getting responses from LLMs...\n",
            "\n",
            "--- GPT-4o Response ---\n",
            "```java\n",
            "public Object streamLoad(HttpServletRequest request,\n",
            "                         @PathVariable(value = DB_KEY) String db,\n",
            "                         @PathVariable(value = TABLE_KEY) String table) {\n",
            "    if (isGroupCommitEnabled(request)) { // Extracted repeated logic into a separate method\n",
            "        try {\n",
            "            String[] pair = new String[]{db, table};\n",
            "            if (isGroupCommitBlock(pair)) {\n",
            "                return new RestBaseResult(\"insert table \" + pair[1] + \" is blocked on schema change\");\n",
            "            }\n",
            "        } catch (Exception e) {\n",
            "            // handle\n",
            "        }\n",
            "    }\n",
            "    return null; // Added return null to ensure method always returns an Object\n",
            "}\n",
            "\n",
            "@RequestMapping(path = \"/api/_http_stream\", method = RequestMethod.PUT)\n",
            "public Object streamLoadWithSql(HttpServletRequest request, HttpServletResponse response) {\n",
            "    String sql = request.getHeader(\"sql\");\n",
            "    LOG.info(\"streaming load sql={}\", sql);\n",
            "    if (isGroupCommitEnabled(request)) { // Reused extracted method for group commit logic\n",
            "        try {\n",
            "            String[] pair = parseDbAndTb(sql);\n",
            "            if (isGroupCommitBlock(pair)) {\n",
            "                return new RestBaseResult(\"insert table \" + pair[1] + \" is blocked on schema change\");\n",
            "            }\n",
            "        } catch (Exception e) {\n",
            "            // handle\n",
            "        }\n",
            "    }\n",
            "    return null; // Added return null to ensure method always returns an Object\n",
            "}\n",
            "\n",
            "private boolean isGroupCommitEnabled(HttpServletRequest request) { // Created new method for repeated logic\n",
            "    String groupCommitStr = request.getHeader(\"group_commit\");\n",
            "    return groupCommitStr != null && groupCommitStr.equals(\"async_mode\");\n",
            "}\n",
            "\n",
            "private boolean isGroupCommitBlock(String[] pair) throws TException {\n",
            "    Database dbObj = getDatabase(pair[0]); // Extracted repeated logic into a separate method\n",
            "    Table tblObj = dbObj.getTableOrException(pair[1], \n",
            "                    s -> new TException(\"table is invalid: \" + s));\n",
            "    return Env.getCurrentEnv().getGroupCommitManager().isBlock(tblObj.getId());\n",
            "}\n",
            "\n",
            "private Database getDatabase(String dbName) throws TException { // New method for fetching Database object\n",
            "    String fullDbName = getFullDbName(dbName);\n",
            "    return Env.getCurrentInternalCatalog().getDbOrException(fullDbName, \n",
            "           s -> new TException(\"database is invalid for dbName: \" + s));\n",
            "}\n",
            "```\n",
            "------------------------------\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969559cc-b524-43e0-8c44-32693a24d14a",
        "id": "ctl_WIffRwvQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}